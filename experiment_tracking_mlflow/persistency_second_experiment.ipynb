{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Python version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same code present in `persistency_base_model - modified data2.ipynb`. I have just copied the notebook and renamed it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "%matplotlib inline\n",
    "\n",
    "from feature_engine import encoding as ce\n",
    "from feature_engine import imputation as mdi\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing mlflow and setting tracking uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"persistency-prediction-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILEPATH = 'data'\n",
    "INPUT_FILENAME = 'master_data_final.csv'\n",
    "\n",
    "INDEX = 'policy_number'\n",
    "DATE_COLS = ['proposal_received_date', 'policy_issue_date', 'agent_dob', 'agent_doj']\n",
    "NA_VALUES = ['', 'NA', 'N/A', 'NULL', 'null', '?', '*', '#N/A', '#VALUE!']\n",
    "DTYPE_DICT = {'zipcode': 'str', 'agent_code': 'str'} ## THese columns should be string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(INPUT_FILEPATH, INPUT_FILENAME):\n",
    "    input_df = pd.read_csv(os.path.join(INPUT_FILEPATH, INPUT_FILENAME),\n",
    "                      index_col = INDEX,\n",
    "                      na_values = NA_VALUES,\n",
    "                      parse_dates = DATE_COLS,\n",
    "                      dayfirst = True,\n",
    "                      dtype = DTYPE_DICT)\n",
    "                    \n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = load_data(INPUT_FILEPATH, INPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target variable distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df['lapse'].value_counts()/len(input_df)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating feature: time_to_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_to_issue(df) -> pd.DataFrame:\n",
    "    df['time_to_issue'] = (df['policy_issue_date'] - df['proposal_received_date']).dt.days\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = create_time_to_issue(input_df)\n",
    "input_df['time_to_issue'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating feature: prem_to_income_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prem_to_income_ratio(df) -> pd.DataFrame:\n",
    "    df['prem_to_income_ratio'] = np.where(df['income'] == 0, 0, (df['annual_premium']/df['income']))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = create_prem_to_income_ratio(input_df)\n",
    "input_df['prem_to_income_ratio'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "The objective of this exercise is to create a demoable solution (maybe not the best possible one, given the augmented data). Hence, we are not going to deep dive into EDA and hypothesis testing. Instead, we will focus on building the ML product using different technologies. \n",
    "\n",
    "## --------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_TO_REM = ['proposal_received_date','policy_issue_date', 'zipcode', 'county', 'state', 'agent_code', 'agent_dob', 'agent_doj']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `proposal_received_date`: Derived `time_to_issue` from this column\n",
    "- `policy_issue_date`: Derived `time_to_issue` from this column\n",
    "- `zipcode`: Too many values, high cardinality\n",
    "- `county`: Too many values, high cardinality\n",
    "- `state`: Too many values, high cardinality\n",
    "- `agent_code`: Id column\n",
    "- `agent_dob`: Derived `agent_age` from this column\n",
    "- `agent_doj`: Derived `agent_tenure_days` from this column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, COLS_TO_REM) -> pd.DataFrame:\n",
    "    df = df.drop(COLS_TO_REM, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = filter_df(input_df, COLS_TO_REM)\n",
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have only one column where missing value is present. `agent_persistency`. Impute missing value with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_persistency_missing_perc = round(temp_df['agent_persistency'].isnull().mean()*100,2)\n",
    "\n",
    "print(f'Total missing percentage of column agent_persistency is: {agent_persistency_missing_perc}% ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_COL = ['agent_persistency']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_HOT_COLS = ['owner_gender', 'marital_status', 'smoker', 'medical', 'education', 'occupation', 'payment_freq',  \n",
    "                'agent_status', 'agent_education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalisation\n",
    "\n",
    "We will normalise the columns using `StandardScaler` because we have values at different scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['owner_age', 'owner_gender', 'marital_status', 'num_nominee', 'smoker',\n",
    "       'medical', 'education', 'occupation', 'experience', 'income',\n",
    "       'negative_zipcode', 'family_member', 'existing_num_policy',\n",
    "       'has_critical_health_history', 'policy_term', 'payment_freq',\n",
    "       'annual_premium', 'sum_insured', 'agent_status', 'agent_education',\n",
    "       'agent_age', 'agent_tenure_days', 'agent_persistency',\n",
    "       'last_6_month_submissions', 'average_premium', 'is_reinstated',\n",
    "       'prev_persistency', 'num_complaints', 'target_completion_perc',\n",
    "       'has_contacted_in_last_6_months', 'credit_score',\n",
    "       'time_to_issue', 'prem_to_income_ratio']\n",
    "\n",
    "TARGET = 'lapse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(temp_df[FEATURES],\n",
    "                                                    temp_df[TARGET],\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state = 786, \n",
    "                                                    shuffle = True,\n",
    "                                                    stratify = temp_df[TARGET])\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_pipe = Pipeline([\n",
    "    \n",
    "    ('imputer_num', mdi.MeanMedianImputer(imputation_method = 'median', variables = MISSING_COL )), \n",
    "    \n",
    "    ('onehot_encoder', ce.OneHotEncoder(top_categories=None,\n",
    "                                        variables= ONE_HOT_COLS,\n",
    "                                        drop_last=True)),\n",
    "    \n",
    "    ('normalisation', StandardScaler())\n",
    "    \n",
    "    # ('clf', LogisticRegression(penalty,random_state = 786))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf = model_input_pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(X_train_trf, label = y_train)\n",
    "X_test_trf = model_input_pipe.transform(X_test)\n",
    "valid = xgb.DMatrix(X_test_trf, label = y_test) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running xgboost with hyperopt and tracking using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"developer\", \"tanmoy\")\n",
    "        mlflow.set_tag(\"model\", \"xgboost hyperparam\")\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        booster = xgb.train(params = params,\n",
    "                            dtrain = train,\n",
    "                            num_boost_round = 1000,\n",
    "                            evals = [(valid, \"validation\")],\n",
    "                            early_stopping_rounds = 50)\n",
    "\n",
    "        \n",
    "        y_pred = booster.predict(valid).round()\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "        return {\"loss\": -accuracy, 'status': STATUS_OK}                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space =  {\n",
    "    'max_depth' : scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'learning_rate' : hp.loguniform('learning_rate', -3, 0),\n",
    "    'min_child_weight' : hp.loguniform('min_child_weight', -1, 3),\n",
    "    'objective' : 'binary:logistic',\n",
    "    'seed' : 786\n",
    "}\n",
    "\n",
    "best_result = fmin(\n",
    "\n",
    "    fn = objective,\n",
    "    space = search_space,\n",
    "    algo = tpe.suggest,\n",
    "    max_evals = 20,\n",
    "    trials = Trials()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Persistency-1bw1YpJo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "1e30edc846a700ed52d786cf8a77501bf87711068f2d1ddfcfe069da441799cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
